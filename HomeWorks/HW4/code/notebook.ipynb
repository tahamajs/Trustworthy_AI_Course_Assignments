{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28937901",
   "metadata": {},
   "source": [
    "# HW4 — Worked examples\n",
    "\n",
    "This notebook demonstrates (Q1) Neural Cleanse *demo*, (Q2) Laplace mechanism examples, and (Q3) Fairness pipeline using `data.csv`. Run the cells in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf607bfc",
   "metadata": {},
   "source": [
    "## Q3 — Fairness (end-to-end demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04554c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairness import load_data, train_baseline_model, accuracy, disparate_impact, zemel_proxy_fairness, apply_promotion_demotion, retrain_with_swapped_labels\n",
    "\n",
    "# load data\n",
    "Xdf, y = load_data('data.csv')\n",
    "sensitive = Xdf['gender'].to_numpy()\n",
    "# numeric features only for the simple baseline\n",
    "Xnum = Xdf.select_dtypes(include=[np.number]).drop(columns=['gender']).to_numpy()\n",
    "Xtrain, Xtest, ytrain, ytest, sens_train, sens_test = train_test_split(Xnum, y.to_numpy(), sensitive, test_size=0.3, random_state=0)\n",
    "clf = train_baseline_model(Xtrain, ytrain)\n",
    "Xs_test = clf._scaler.transform(Xtest)\n",
    "yproba = clf.predict_proba(Xs_test)[:,1]\n",
    "ypred = (yproba >= 0.5).astype(int)\n",
    "print('Baseline accuracy:', accuracy(ytest, ypred))\n",
    "print('Baseline disparate impact:', disparate_impact(ytest, ypred, sens_test))\n",
    "print('Baseline Zemel-proxy fairness:', zemel_proxy_fairness(Xs_test, ypred, sens_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b926c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply promotion/demotion mitigation\n",
    "k = 10  # swap budget (example)\n",
    "swap_mask = apply_promotion_demotion(Xs_test, yproba, ytest.to_numpy(), sens_test, k)\n",
    "clf2 = retrain_with_swapped_labels(Xtrain, ytrain, swap_mask[:Xtrain.shape[0]] if swap_mask.size> Xtrain.shape[0] else swap_mask)\n",
    "Xs_test2 = clf2._scaler.transform(Xtest)\n",
    "yproba2 = clf2.predict_proba(Xs_test2)[:,1]\n",
    "ypred2 = (yproba2 >= 0.5).astype(int)\n",
    "print('Post-mitigation accuracy:', accuracy(ytest, ypred2))\n",
    "print('Post-mitigation disparate impact:', disparate_impact(ytest, ypred2, sens_test))\n",
    "print('Post-mitigation Zemel-proxy fairness:', zemel_proxy_fairness(Xs_test2, ypred2, sens_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0280ee",
   "metadata": {},
   "source": [
    "## Q2 — Laplace mechanism examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy import laplace_scale, add_laplace_noise, laplace_cdf_threshold, compose_epsilons\n",
    "# Example: average income sensitivity and scale (fill with your problem numbers)\n",
    "sens_avg = 200000/500.0  # example sensitivity for mean (replace with actual)\n",
    "eps = 1.0\n",
    "print('scale b for average:', laplace_scale(sens_avg, eps))\n",
    "# probability example: P(noisy_response > threshold)\n",
    "print('P(noisy > 505):', laplace_cdf_threshold(505, 500, sensitivity=1.0, epsilon=0.5))\n",
    "print('Composition (0.5 + 0.5) ->', compose_epsilons([0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8d245",
   "metadata": {},
   "source": [
    "## Q1 — Neural Cleanse (demo run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_cleanse import load_model, reconstruct_trigger, detect_outlier_scales\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# demo model + random data\n",
    "model = load_model(demo=True, device='cpu')\n",
    "X = torch.rand(200,1,28,28)\n",
    "y = torch.randint(0,10,(200,))\n",
    "ds = TensorDataset(X,y)\n",
    "loader = DataLoader(ds, batch_size=32)\n",
    "scales = []\n",
    "for lbl in range(10):\n",
    "    _,_,s = reconstruct_trigger(model, loader, lbl, device='cpu', steps=200, lr=0.2)\n",
    "    scales.append(s)\n",
    "print('scales:', scales)\n",
    "print('detected attacked (demo):', detect_outlier_scales(scales))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
