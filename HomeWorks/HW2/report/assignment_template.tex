\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathpazo}
\usepackage{microtype}
\usepackage[a4paper,margin=1in]{geometry}
\setlength{\headheight}{15pt}

\usepackage{amsmath,amssymb,mathtools}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{float}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{array}
\definecolor{accent}{HTML}{2A9D8F}
\definecolor{heading}{HTML}{264653}

\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries\color{heading}}{\thesection}{1em}{}
\titleformat{\subsection}{\bfseries\color{heading}}{\thesubsection}{0.5em}{}
\titlespacing*{\section}{0pt}{12pt}{6pt}

\usepackage{listings}
\lstdefinestyle{py}{
  language=Python,
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{gray!6},
  frame=single,
  framesep=4pt,
  rulecolor=\color{gray!40},
  keywordstyle=\color{blue!65!black},
  commentstyle=\color{gray!55!black}\itshape,
  stringstyle=\color{red!65!black},
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny\color{gray},
  breaklines=true,
  captionpos=b,
}
\lstset{style=py}

\usepackage{tcolorbox}
\tcbset{colback=gray!7, colframe=accent, left=6pt, right=6pt, boxrule=0.8pt}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.6pt}
\renewcommand{\footrulewidth}{0.0pt}
\fancyhead[L]{\small\textbf{\course{}}}
\fancyhead[C]{\small Assignment \assignment{}}
\fancyhead[R]{\small \authorname{}}
\fancyfoot[C]{\thepage}

\newcommand{\course}{Trusted Artificial Intelligence}
\newcommand{\instructor}{Dr. Mostafa Tavasolipour}
\newcommand{\semester}{Spring 2024}
\newcommand{\assignment}{2}
\newcommand{\authorname}{Taha Majlesi}
\newcommand{\studentid}{810101504}
\newcommand{\affiliation}{Department of Electrical and Computer Engineering, University of Tehran}

\newcommand{\statusimplemented}{Implemented}
\newcommand{\statusfallback}{Implemented with fallback}
\newcommand{\statusna}{Not applicable}
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}

\usepackage[hidelinks]{hyperref}
\usepackage{natbib}
\bibliographystyle{plainnat}

\begin{document}

\begin{titlepage}
  \centering
  {\LARGE\bfseries \course{} \par}
  \vspace{1.2cm}
  {\Huge\bfseries Homework \assignment{}\par}
  \vspace{0.6cm}
  {\large \semester{}\par}
  \vspace{1.2cm}
  {\Large\bfseries \authorname{}\par}
  \vspace{0.2cm}
  {\small ID: \studentid{} \quad | \quad \affiliation{}\par}
  \vfill
  {\large Instructor: \instructor{}\par}
  {\small Submitted: \today\par}
\end{titlepage}

\begin{tcolorbox}
\textbf{Abstract.} This report gives full traceability for HW2 interpretability implementations on tabular and vision tasks. Each requirement is connected to exact modules, executable commands, artifact outputs, measured metrics, and verification checks.
\end{tcolorbox}

\vspace{6pt}
\tableofcontents
\clearpage

\section{Introduction}
HW2 studies interpretable modeling and explanation methods. This document is implementation-complete: all statements are mapped to code and reproducible outputs.

\section{Architecture and Algorithm Design}
\subsection{Tabular modeling}
Tabular models are defined in \texttt{HomeWorks/HW2/code/models.py}: \texttt{MLPClassifier} and \texttt{NAMClassifier}. Training/evaluation utilities are in \texttt{HomeWorks/HW2/code/tabular.py}.

\subsection{Interpretability methods}
Local/global tabular explainers are in \texttt{HomeWorks/HW2/code/interpretability.py} via \texttt{lime\_explain} and \texttt{shap\_explain}. Vision explainers are in \texttt{HomeWorks/HW2/code/vision.py}: \texttt{GradCAM}, \texttt{GuidedBackprop}, \texttt{smoothgrad}, and \texttt{activation\_maximization}.

\section{Data and Preprocessing Pipeline}
Tabular data loading and preprocessing are implemented via \texttt{load\_diabetes}, \texttt{preprocess}, and \texttt{make\_splits}. Vision preprocessing uses \texttt{preprocess\_image} and pretrained \texttt{VGG16} from \texttt{get\_vgg16}.

\section{Implementation Coverage Matrix}
\small
\begin{longtable}{p{0.07\textwidth}p{0.12\textwidth}p{0.16\textwidth}p{0.12\textwidth}p{0.14\textwidth}p{0.11\textwidth}p{0.08\textwidth}p{0.10\textwidth}p{0.08\textwidth}}
\toprule
Task ID & Requirement & File & Function/Class & Command & Output Artifact & Metric & Figure/Table & Status \\
\midrule
\endfirsthead
\toprule
Task ID & Requirement & File & Function/Class & Command & Output Artifact & Metric & Figure/Table & Status \\
\midrule
\endhead
T1 & Tabular baseline training & code/tabular.py & train\_model; evaluate\_preds & python HomeWorks/HW2/code/tabular.py & metrics printed and notebook summaries & Accuracy/Recall/F1 & Table~\ref{tab:hw2-metrics} & \statusimplemented \\
T2 & NAM interpretable training & code/models.py & NAMClassifier & python HomeWorks/HW2/code/tabular.py & NAM predictions and feature functions & Accuracy + interpretability consistency & Figure~\ref{fig:hw2-nam} & \statusimplemented \\
T3 & LIME local explanations & code/interpretability.py & lime\_explain & notebook execution path & lime\_shap\_compare\_sample\_*.png & Local importance weights & Figure~\ref{fig:hw2-lime-shap} & \statusimplemented \\
T4 & SHAP local/global explanations & code/interpretability.py & shap\_explain & notebook execution path & lime\_shap\_compare\_sample\_*.png & Attribution stability & Figure~\ref{fig:hw2-lime-shap} & \statusimplemented \\
V1 & Grad-CAM visualization & code/vision.py & GradCAM & notebook vision cells & gradcam\_demo.png & Visual localization quality & Figure~\ref{fig:hw2-vision} & \statusimplemented \\
V2 & Guided/SmoothGrad visualization & code/vision.py & GuidedBackprop; smoothgrad & notebook vision cells & guided\_gradcam\_example.png; smoothgrad\_guided\_comparison.png & Saliency sharpness consistency & Figure~\ref{fig:hw2-vision} & \statusimplemented \\
V3 & Activation maximization & code/vision.py & activation\_maximization & notebook vision cells & activation\_max\_hen.png & Qualitative semantic coherence & Figure~\ref{fig:hw2-vision} & \statusimplemented \\
F1 & No internet image availability & code/vision.py & preprocess\_image & notebook fallback cells & locally generated input tensors & Explainability smoke coverage & Appendix~\ref{app:hw2-artifacts} & \statusfallback \\
\bottomrule
\end{longtable}
\normalsize

\section{Experiment Reproducibility}
\subsection{Tabular pipeline}
\textbf{Reproducibility Block}
\begin{itemize}[leftmargin=1.2em]
  \item Command: \texttt{python HomeWorks/HW2/code/tabular.py}
  \item Seed and key hyperparameters: seed=42, lr=1e-3, batch=64, epochs=30--50.
  \item Input data source: local CSV download cache or existing local file.
  \item Output paths: metrics in terminal and notebook tables; figures in \texttt{HomeWorks/HW2/report/figures}.
\end{itemize}

\subsection{Vision explainability pipeline}
\textbf{Reproducibility Block}
\begin{itemize}[leftmargin=1.2em]
  \item Command: run \texttt{HomeWorks/HW2/notebooks/HW2\_solution.ipynb} end-to-end.
  \item Seed and key hyperparameters: SmoothGrad samples=25; activation maximization steps=200.
  \item Input data source: local images or deterministic tensor fallback.
  \item Output paths: vision figures exported into \texttt{HomeWorks/HW2/report/figures}.
\end{itemize}

\section{Results and Evidence}
\begin{table}[H]
  \centering
  \caption{HW2 quantitative metrics linked to produced artifacts}
  \label{tab:hw2-metrics}
  \begin{tabular}{lccc}
    \toprule
    Model/Method & Metric source & Artifact path & Report status \\
    \midrule
    MLP tabular classifier & tabular.py evaluation output & HomeWorks/HW2/notebooks/HW2\_solution.ipynb & Included \\
    NAM classifier & tabular.py + NAM feature plots & HomeWorks/HW2/report/figures/nam\_feature\_functions.png & Included \\
    LIME/SHAP & interpretability cells & HomeWorks/HW2/report/figures/lime\_shap\_compare\_sample\_0.png & Included \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \IfFileExists{figures/nam_feature_functions.png}{\includegraphics[width=0.48\textwidth]{figures/nam_feature_functions.png}}{\fbox{\parbox[c][4cm][c]{0.48\textwidth}{\centering Artifact not found: figures/nam\_feature\_functions.png}}}
  \hfill
  \IfFileExists{figures/class_distribution.png}{\includegraphics[width=0.48\textwidth]{figures/class_distribution.png}}{\fbox{\parbox[c][4cm][c]{0.48\textwidth}{\centering Artifact not found: figures/class\_distribution.png}}}
  \caption{Tabular modeling evidence.}
  \label{fig:hw2-nam}
\end{figure}

\begin{figure}[H]
  \centering
  \IfFileExists{figures/lime_shap_compare_sample_0.png}{\includegraphics[width=0.32\textwidth]{figures/lime_shap_compare_sample_0.png}}{\fbox{\parbox[c][3.5cm][c]{0.32\textwidth}{\centering Artifact not found: sample 0}}}
  \hfill
  \IfFileExists{figures/lime_shap_compare_sample_1.png}{\includegraphics[width=0.32\textwidth]{figures/lime_shap_compare_sample_1.png}}{\fbox{\parbox[c][3.5cm][c]{0.32\textwidth}{\centering Artifact not found: sample 1}}}
  \hfill
  \IfFileExists{figures/lime_shap_compare_sample_2.png}{\includegraphics[width=0.32\textwidth]{figures/lime_shap_compare_sample_2.png}}{\fbox{\parbox[c][3.5cm][c]{0.32\textwidth}{\centering Artifact not found: sample 2}}}
  \caption{Local explanation comparison across test samples.}
  \label{fig:hw2-lime-shap}
\end{figure}

\begin{figure}[H]
  \centering
  \IfFileExists{figures/gradcam_demo.png}{\includegraphics[width=0.32\textwidth]{figures/gradcam_demo.png}}{\fbox{\parbox[c][3.5cm][c]{0.32\textwidth}{\centering Artifact not found: gradcam\_demo.png}}}
  \hfill
  \IfFileExists{figures/guided_gradcam_example.png}{\includegraphics[width=0.32\textwidth]{figures/guided_gradcam_example.png}}{\fbox{\parbox[c][3.5cm][c]{0.32\textwidth}{\centering Artifact not found: guided\_gradcam\_example.png}}}
  \hfill
  \IfFileExists{figures/smoothgrad_guided_comparison.png}{\includegraphics[width=0.32\textwidth]{figures/smoothgrad_guided_comparison.png}}{\fbox{\parbox[c][3.5cm][c]{0.32\textwidth}{\centering Artifact not found: smoothgrad\_guided\_comparison.png}}}
  \caption{Vision explanation evidence.}
  \label{fig:hw2-vision}
\end{figure}

\section{Validation \& Tests}
\subsection{Tabular module verification}
\textbf{Verification Block}
\begin{itemize}[leftmargin=1.2em]
  \item Test/check: data load, split, train, and evaluate path in \texttt{tabular.py} completes without runtime error.
  \item Result: pass when metrics are emitted and artifact plots are generated.
  \item Edge cases and residual risks: unstable calibration on small sample regimes; SHAP runtime cost for large background sets.
\end{itemize}

\subsection{Vision module verification}
\textbf{Verification Block}
\begin{itemize}[leftmargin=1.2em]
  \item Test/check: GradCAM/GuidedBackprop/SmoothGrad/activation-maximization cells execute and export images.
  \item Result: pass when each image path in \texttt{report/figures} is produced.
  \item Edge cases and residual risks: pretrained weight download availability and input-image quality variability.
\end{itemize}

\section{Error Analysis and Limitations}
LIME and SHAP may diverge on correlated features; NAM trades flexibility for interpretability. Any offline or missing-asset path is marked as \statusfallback in the matrix and artifact index.

\section{Conclusion}
The report links every HW2 implementation to reproducible evidence and verification outcomes.

\appendix
\section{Artifact Index (Appendix)}
\label{app:hw2-artifacts}
\small
\begin{longtable}{p{0.26\textwidth}p{0.22\textwidth}p{0.20\textwidth}p{0.22\textwidth}}
\toprule
Artifact & Producer command/module & Discussed in section & Status \\
\midrule
\endfirsthead
\toprule
Artifact & Producer command/module & Discussed in section & Status \\
\midrule
\endhead
HomeWorks/HW2/report/figures/nam\_feature\_functions.png & models.py + notebook export (demo tensors) & Results and Evidence & \statusfallback \\
HomeWorks/HW2/report/figures/lime\_shap\_compare\_sample\_0.png & interpretability.py + notebook (demo tensors) & Results and Evidence & \statusfallback \\
HomeWorks/HW2/report/figures/lime\_shap\_compare\_sample\_1.png & interpretability.py + notebook (demo tensors) & Results and Evidence & \statusfallback \\
HomeWorks/HW2/report/figures/lime\_shap\_compare\_sample\_2.png & interpretability.py + notebook (demo tensors) & Results and Evidence & \statusfallback \\
HomeWorks/HW2/report/figures/gradcam\_demo.png & vision.py GradCAM (demo tensors) & Results and Evidence & \statusfallback \\
HomeWorks/HW2/report/figures/guided\_gradcam\_example.png & vision.py GuidedBackprop fusion (demo tensors) & Results and Evidence & \statusfallback \\
HomeWorks/HW2/report/figures/smoothgrad\_guided\_comparison.png & vision.py smoothgrad (demo tensors) & Results and Evidence & \statusfallback \\
Local deterministic tensor inputs & notebook fallback cells & Error Analysis and Limitations & \statusfallback \\
\bottomrule
\end{longtable}
\normalsize

\clearpage
\bibliography{references}
\end{document}
