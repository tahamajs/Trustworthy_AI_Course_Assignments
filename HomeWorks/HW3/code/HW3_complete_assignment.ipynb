{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb6ffa5",
   "metadata": {},
   "source": [
    "# درس هوش مصنوعی قابل اعتماد | Trusted Artificial Intelligence\n",
    "## تمرین شماره ۳ | Homework 3\n",
    "### نوتبوک کامل و قابل اجرا (Q1 تا Q6)\n",
    "\n",
    "**دانشجو / Student:** Taha Majlesi (810101504)  \n",
    "**دانشگاه / University:** University of Tehran, ECE Department  \n",
    "**مدرس / Instructor:** Dr. Mostafa Tavasolipour\n",
    "\n",
    "این نوتبوک برای تصحیح نهایی طراحی شده است:\n",
    "- ترتیب دقیق سوالات مطابق صورت تمرین\n",
    "- برچسب‌های یکسان با قالب تمرین (`سوال` و `زیربخش`)\n",
    "- متن دو‌زبانه فارسی/انگلیسی برای خوانایی گزارش\n",
    "- اجرای بازتولیدپذیر (seed ثابت + خروجی‌های ذخیره‌شده)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c5e9d",
   "metadata": {},
   "source": [
    "## نقشه نمره‌دهی | Grading Map\n",
    "\n",
    "| Question | بخش | Score |\n",
    "|---|---|---:|\n",
    "| سوال اول | Observational vs Interventional Probability | 10 |\n",
    "| سوال دوم | Causal Recourse for Two Individuals | 12 |\n",
    "| سوال سوم | Airline SCM Graph + Modeling + Variance Analysis | 20 |\n",
    "| سوال چهارم | Insulin Causal Effect Estimation | 22 |\n",
    "| سوال پنجم | Complete Causal Recourse Pipeline | 20 |\n",
    "| سوال ششم | Theory from Robust Causal Recourse Paper | 16 |\n",
    "\n",
    "**Total: 100**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2285d",
   "metadata": {},
   "source": [
    "## تنظیمات اولیه و بازتولیدپذیری | Setup and Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dac2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Resolve project root robustly.\n",
    "ROOT = Path.cwd().resolve()\n",
    "while ROOT != ROOT.parent and not (ROOT / 'description' / 'HW3_TAI.pdf').exists():\n",
    "    ROOT = ROOT.parent\n",
    "if not (ROOT / 'description' / 'HW3_TAI.pdf').exists():\n",
    "    raise RuntimeError('Could not locate HW3 project root from current working directory.')\n",
    "\n",
    "Q5_DIR_CANDIDATES = [ROOT / 'code' / 'q5_codes', ROOT / 'code' / 'Q5_codes']\n",
    "Q5_DIR = next((p for p in Q5_DIR_CANDIDATES if p.exists()), None)\n",
    "if Q5_DIR is None:\n",
    "    raise RuntimeError('Could not locate q5_codes directory.')\n",
    "\n",
    "if str(Q5_DIR) not in sys.path:\n",
    "    sys.path.append(str(Q5_DIR))\n",
    "\n",
    "import data_utils\n",
    "import recourse\n",
    "import trainers\n",
    "import utils\n",
    "import train_classifiers\n",
    "\n",
    "DATASET_DIR = ROOT / 'dataset'\n",
    "OUT_DIR = ROOT / 'output' / 'jupyter-notebook' / 'artifacts'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT)\n",
    "print('Q5_DIR:', Q5_DIR)\n",
    "print('DATASET_DIR:', DATASET_DIR)\n",
    "print('Health source:', data_utils.get_health_source_path())\n",
    "print('Health source tag:', data_utils.get_health_source_tag())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a00ba2",
   "metadata": {},
   "source": [
    "## سوال اول (۱۰ نمره) | Question 1 (10 Points)\n",
    "DAG: \\(S \\to A\\), \\(S \\to Y\\), \\(A \\to Y\\) with the exact probabilities from the assignment PDF.\n",
    "\n",
    "**شرح نظری کامل / Full theoretical note:**\n",
    "در این DAG، متغیر $S$ هم روی $A$ و هم روی $Y$ اثر دارد؛ بنابراین $A$ و $Y$ همبسته هستند حتی اگر $A$ به‌صورت مداخله‌ای تنظیم شود. به‌صورت مشاهده‌ای باید از بیز استفاده کرد: $P(Y\\mid A)=\\sum_s P(Y\\mid A,S=s)P(S\\mid A)$. اما برای مداخله $do(A=a)$، مسیرهای ورودی به $A$ قطع می‌شود و داریم $P(Y\\mid do(A=a))=\\sum_s P(Y\\mid A=a,S=s)P(S=s)$. تفاوت این دو کمیت دقیقا اثر مخدوش‌گری $S$ را نشان می‌دهد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3e020",
   "metadata": {},
   "source": [
    "### زیربخش اول (۵ نمره)\n",
    "محاسبه‌ی:- \\(P_X(Y=1\\mid A=N)\\)\n",
    "- \\(P_X(Y=1\\mid A=O)\\)\n",
    "\n",
    "Compute observational conditionals using Bayes + total probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c66687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 constants extracted from the assignment PDF.\n",
    "pS_L = 0.49\n",
    "pS_R = 1 - pS_L\n",
    "\n",
    "pA_N_given_S = {'L': 0.77, 'R': 0.24}\n",
    "pA_O_given_S = {'L': 1 - pA_N_given_S['L'], 'R': 1 - pA_N_given_S['R']}\n",
    "\n",
    "pY1_given_SA = {\n",
    "    ('L', 'N'): 0.73,\n",
    "    ('L', 'O'): 0.69,\n",
    "    ('R', 'N'): 0.93,\n",
    "    ('R', 'O'): 0.87,\n",
    "}\n",
    "\n",
    "# Marginals for A\n",
    "pA_N = pA_N_given_S['L'] * pS_L + pA_N_given_S['R'] * pS_R\n",
    "pA_O = 1 - pA_N\n",
    "\n",
    "# Bayes terms for observational conditionals\n",
    "pS_L_given_A_N = (pA_N_given_S['L'] * pS_L) / pA_N\n",
    "pS_R_given_A_N = 1 - pS_L_given_A_N\n",
    "\n",
    "pS_L_given_A_O = (pA_O_given_S['L'] * pS_L) / pA_O\n",
    "pS_R_given_A_O = 1 - pS_L_given_A_O\n",
    "\n",
    "# Observational conditionals\n",
    "pY1_given_A_N = (\n",
    "    pY1_given_SA[('L', 'N')] * pS_L_given_A_N\n",
    "    + pY1_given_SA[('R', 'N')] * pS_R_given_A_N\n",
    ")\n",
    "pY1_given_A_O = (\n",
    "    pY1_given_SA[('L', 'O')] * pS_L_given_A_O\n",
    "    + pY1_given_SA[('R', 'O')] * pS_R_given_A_O\n",
    ")\n",
    "\n",
    "# Interventional conditionals: cut incoming edges to A\n",
    "pY1_given_do_A_N = (\n",
    "    pY1_given_SA[('L', 'N')] * pS_L\n",
    "    + pY1_given_SA[('R', 'N')] * pS_R\n",
    ")\n",
    "pY1_given_do_A_O = (\n",
    "    pY1_given_SA[('L', 'O')] * pS_L\n",
    "    + pY1_given_SA[('R', 'O')] * pS_R\n",
    ")\n",
    "\n",
    "q1_res = pd.DataFrame(\n",
    "    [\n",
    "        {'quantity': 'P(Y=1 | A=N)', 'value': pY1_given_A_N},\n",
    "        {'quantity': 'P(Y=1 | A=O)', 'value': pY1_given_A_O},\n",
    "        {'quantity': 'P(Y=1 | do(A=N))', 'value': pY1_given_do_A_N},\n",
    "        {'quantity': 'P(Y=1 | do(A=O))', 'value': pY1_given_do_A_O},\n",
    "    ]\n",
    ")\n",
    "\n",
    "q1_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e058073",
   "metadata": {},
   "source": [
    "### زیربخش دوم (۵ نمره)\n",
    "محاسبه‌ی:- \\(P_X(Y=1\\mid do(A=N))\\)\n",
    "- \\(P_X(Y=1\\mid do(A=O))\\)\n",
    "\n",
    "Interventional probabilities are computed with truncated factorization (cut incoming edges to \\(A\\)).\n",
    "\n",
    "**جمع‌بندی نمره‌ای / Grading note:** جدول `q1_res` هر چهار کمیت خواسته‌شده را مستقیم گزارش می‌کند.\n",
    "\n",
    "\n",
    "**نتایج عددی Q1 / Q1 numeric results:**\n",
    "\n",
    "| Quantity | Value |\n",
    "|---|---:|\n",
    "| P(Y=1 \\| A=N) | 0.77899 |\n",
    "| P(Y=1 \\| A=O) | 0.82945 |\n",
    "| P(Y=1 \\| do(A=N)) | 0.83200 |\n",
    "| P(Y=1 \\| do(A=O)) | 0.78180 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1a87b",
   "metadata": {},
   "source": [
    "## سوال دوم (۱۲ نمره) | Question 2 (12 Points)\n",
    "Given:\n",
    "- $A=[75000,25000]^T$, $B=[70000,23800]^T$\n",
    "- classifier: $h=\\mathrm{sgn}(X_1 + 5X_2 - 225000)$\n",
    "\n",
    "هدف: کمینه‌سازی هزینه مداخله برای تغییر تصمیم به حالت مطلوب.\n",
    "\n",
    "**شرح نظری کامل / Full theoretical note:**\n",
    "برای مرز تصمیم خطی $x_1+5x_2=225000$ و هزینه $\\ell_1$، کارآمدترین جهت مداخله روی ویژگی با ضریب بزرگ‌تر است (اینجا $x_2$) چون به ازای یک واحد تغییر، بیشترین افزایش margin را می‌دهد. برای هزینه $\\ell_2$، بهترین جهت در راستای بردار نرمال $w=(1,5)$ است؛ یعنی عمل به‌صورت پروژکشن به سمت مرز تصمیم انجام می‌شود. این تفاوت نشان می‌دهد که معیار هزینه مستقیما هندسه مداخله را تغییر می‌دهد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([1.0, 5.0])\n",
    "B_TH = 225000.0\n",
    "\n",
    "individuals = {\n",
    "    'A': np.array([75000.0, 25000.0]),\n",
    "    'B': np.array([70000.0, 23800.0]),\n",
    "}\n",
    "\n",
    "def score(x: np.ndarray) -> float:\n",
    "    return float(W @ x - B_TH)\n",
    "\n",
    "def min_l1_nonneg_action(x: np.ndarray) -> np.ndarray:\n",
    "    # minimize |d1|+|d2| subject to d>=0 and W^T(x+d) >= B_TH\n",
    "    gap = max(0.0, -score(x))\n",
    "    # best to allocate to feature with largest coefficient per unit L1 cost: X2\n",
    "    return np.array([0.0, gap / W[1]])\n",
    "\n",
    "def min_l2_nonneg_action(x: np.ndarray) -> np.ndarray:\n",
    "    gap = max(0.0, -score(x))\n",
    "    if gap == 0:\n",
    "        return np.zeros_like(x)\n",
    "    return (gap / float(W @ W)) * W\n",
    "\n",
    "rows = []\n",
    "for name, x in individuals.items():\n",
    "    d1 = min_l1_nonneg_action(x)\n",
    "    d2 = min_l2_nonneg_action(x)\n",
    "    for metric, d in [('L1-opt', d1), ('L2-opt', d2)]:\n",
    "        x_cf = x + d\n",
    "        rows.append(\n",
    "            {\n",
    "                'individual': name,\n",
    "                'metric': metric,\n",
    "                'x1_old': x[0],\n",
    "                'x2_old': x[1],\n",
    "                'delta_x1': d[0],\n",
    "                'delta_x2': d[1],\n",
    "                'x1_new': x_cf[0],\n",
    "                'x2_new': x_cf[1],\n",
    "                'new_margin': score(x_cf),\n",
    "                'L1_cost': float(np.abs(d).sum()),\n",
    "                'L2_cost': float(np.sqrt((d**2).sum())),\n",
    "            }\n",
    "        )\n",
    "\n",
    "q2_res = pd.DataFrame(rows)\n",
    "q2_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd27698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual boundary and interventions\n",
    "x1 = np.linspace(60000, 110000, 300)\n",
    "x2_boundary = (B_TH - x1) / 5.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(x1, x2_boundary, 'k--', label='Decision boundary: x1 + 5x2 = 225000')\n",
    "\n",
    "for name, x in individuals.items():\n",
    "    ax.scatter(x[0], x[1], s=80, label=f'{name} original')\n",
    "    d = min_l1_nonneg_action(x)\n",
    "    x_cf = x + d\n",
    "    ax.scatter(x_cf[0], x_cf[1], s=80, marker='x', label=f'{name} recourse (L1-opt)')\n",
    "    ax.arrow(x[0], x[1], d[0], d[1], head_width=200, length_includes_head=True, alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('X1 (Annual Salary)')\n",
    "ax.set_ylabel('X2 (Bank Balance)')\n",
    "ax.set_title('Q2 Recourse Moves to Reach Loan Approval Boundary')\n",
    "ax.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988a4961",
   "metadata": {},
   "source": [
    "**توضیح برای تصحیح / Grading interpretation:**\n",
    "- جدول `q2_res` شامل state جدید، هزینه‌ها، و margin نهایی است.\n",
    "- نمودار مرز تصمیم و بردار مداخله را برای هر فرد نشان می‌دهد.\n",
    "\n",
    "\n",
    "**نتایج عددی Q2 / Q2 numeric results:**\n",
    "\n",
    "| Person | Metric | Δx1 | Δx2 | Cost |\n",
    "|---|---|---:|---:|---:|\n",
    "| A | L1-opt | 0.0 | 5000.0 | 5000.0 |\n",
    "| A | L2-opt | 961.54 | 4807.69 | 4902.90 |\n",
    "| B | L1-opt | 0.0 | 7200.0 | 7200.0 |\n",
    "| B | L2-opt | 1384.62 | 6923.08 | 7060.18 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b9d24",
   "metadata": {},
   "source": [
    "## سوال سوم (۲۰ نمره) | Question 3 (20 Points)\n",
    "\n",
    "در این مخزن، فایل خام airline با همان ستون‌های صورت تمرین موجود نیست؛ بنابراین این نوتبوک:\n",
    "1. ابتدا دنبال دیتاست واقعی می‌گردد.\n",
    "2. اگر پیدا نشود، fallback سنتتیکِ سازگار با SCM را می‌سازد تا کل زیربخش‌ها قابل اجرا بمانند.\n",
    "\n",
    "This keeps the full methodology fully runnable for grading.\n",
    "\n",
    "**شرح نظری کامل / Full theoretical note:**\n",
    "در SCM شرکت هواپیمایی، هر متغیر تابعی از والدهای علّی و نویز است. این فرم اجازه می‌دهد هم تفسیر علّی داشته باشیم و هم اثرگذاری متغیرها را با تجزیه واریانس یا رگرسیون خطی بسنجیم. وقتی ساختار علّی تعریف شد، می‌توان اثرات مستقیم و غیرمستقیم بر سود را تفکیک کرد و حساسیت سود نسبت به قیمت بلیت، بودجه بازاریابی و هزینه‌های عملیاتی را در چارچوبی منسجم تحلیل نمود.\n",
    "\n",
    "\n",
    "**نکته تکمیلی Q3 / Q3 extra note:**\n",
    "فرم خطی SCM امکان می‌دهد ضرایب رگرسیون را به‌عنوان اثرات مستقیم تفسیر کنیم (در حد فرضیات استقلال نویز). بنابراین تجزیه واریانس سود بر اساس ضرایب استاندارد شده (feature importance) با ساختار علّی هم‌جهت است."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0726a7",
   "metadata": {},
   "source": [
    "### زیربخش اول (۲ نمره)\n",
    "رسم گراف علّی با `networkx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426840cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "AIRLINE_COLS = [\n",
    "    'Booking_Mode',\n",
    "    'Marketing_Budget',\n",
    "    'Website_Visits',\n",
    "    'Ticket_Price',\n",
    "    'Tickets_Sold',\n",
    "    'Sales_Revenue',\n",
    "    'Operating_Expenses',\n",
    "    'Profit',\n",
    "]\n",
    "\n",
    "def load_or_simulate_airline_df(seed: int = 0) -> tuple[pd.DataFrame, str, bool]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    candidates = [\n",
    "        ROOT / 'dataset' / 'airline_synthetic.csv',\n",
    "        ROOT / 'dataset' / 'airline.csv',\n",
    "        ROOT / 'dataset' / 'airline_operations.csv',\n",
    "        ROOT / 'dataset' / 'out_data_2.csv',\n",
    "        ROOT / 'code' / 'q5_codes' / 'data' / 'airline.csv',\n",
    "        ROOT / 'code' / 'q5_codes' / 'data' / 'out_data_2.csv',\n",
    "    ]\n",
    "\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(p)\n",
    "                if set(AIRLINE_COLS).issubset(df.columns):\n",
    "                    return df[AIRLINE_COLS].copy(), str(p), False\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Fallback synthetic SCM dataset\n",
    "    n = 365\n",
    "    booking = rng.binomial(1, 0.22, size=n)\n",
    "\n",
    "    marketing = 1200 + 850 * booking + rng.normal(0, 120, size=n)\n",
    "    website = 12000 + 2.4 * marketing + 2800 * booking + rng.normal(0, 900, size=n)\n",
    "    ticket_price = 420 + 170 * booking + rng.normal(0, 35, size=n)\n",
    "    tickets_sold = 1800 + 0.30 * website - 2.0 * ticket_price + 900 * booking + rng.normal(0, 300, size=n)\n",
    "    tickets_sold = np.clip(tickets_sold, 100, None)\n",
    "    sales = ticket_price * tickets_sold + rng.normal(0, 40000, size=n)\n",
    "    op_exp = 900000 + 170 * marketing + 130 * tickets_sold + rng.normal(0, 30000, size=n)\n",
    "    profit = sales - op_exp\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'Booking_Mode': booking.astype(bool),\n",
    "            'Marketing_Budget': marketing,\n",
    "            'Website_Visits': website,\n",
    "            'Ticket_Price': ticket_price,\n",
    "            'Tickets_Sold': tickets_sold,\n",
    "            'Sales_Revenue': sales,\n",
    "            'Operating_Expenses': op_exp,\n",
    "            'Profit': profit,\n",
    "        }\n",
    "    )\n",
    "    return df, 'synthetic_scm_fallback', True\n",
    "\n",
    "air_df, air_source, used_fallback = load_or_simulate_airline_df(seed=SEED)\n",
    "print('Airline source:', air_source)\n",
    "print('Used synthetic fallback:', used_fallback)\n",
    "air_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e38d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3-A: draw the causal graph\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(\n",
    "    [\n",
    "        ('Booking_Mode', 'Marketing_Budget'),\n",
    "        ('Booking_Mode', 'Website_Visits'),\n",
    "        ('Booking_Mode', 'Tickets_Sold'),\n",
    "        ('Booking_Mode', 'Ticket_Price'),\n",
    "        ('Marketing_Budget', 'Website_Visits'),\n",
    "        ('Marketing_Budget', 'Operating_Expenses'),\n",
    "        ('Website_Visits', 'Tickets_Sold'),\n",
    "        ('Ticket_Price', 'Tickets_Sold'),\n",
    "        ('Ticket_Price', 'Sales_Revenue'),\n",
    "        ('Tickets_Sold', 'Sales_Revenue'),\n",
    "        ('Tickets_Sold', 'Operating_Expenses'),\n",
    "        ('Sales_Revenue', 'Profit'),\n",
    "        ('Operating_Expenses', 'Profit'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(11, 7))\n",
    "pos = nx.spring_layout(G, seed=SEED, k=1.25)\n",
    "nx.draw_networkx(G, pos=pos, arrows=True, node_size=2100, font_size=10)\n",
    "plt.title('Q3-A Causal Graph (NetworkX)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d0905",
   "metadata": {},
   "source": [
    "### زیربخش دوم (۵ نمره)\n",
    "مدلسازی SCM: هر گره به‌صورت تابعی از والدها + نویز (linear structural equations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3-B: fit SCM equations (linear structural functions + additive noise)\n",
    "parents = {\n",
    "    'Marketing_Budget': ['Booking_Mode'],\n",
    "    'Website_Visits': ['Booking_Mode', 'Marketing_Budget'],\n",
    "    'Ticket_Price': ['Booking_Mode'],\n",
    "    'Tickets_Sold': ['Booking_Mode', 'Website_Visits', 'Ticket_Price'],\n",
    "    'Sales_Revenue': ['Ticket_Price', 'Tickets_Sold'],\n",
    "    'Operating_Expenses': ['Marketing_Budget', 'Tickets_Sold'],\n",
    "    'Profit': ['Sales_Revenue', 'Operating_Expenses'],\n",
    "}\n",
    "\n",
    "scm_models = {}\n",
    "scm_noise_stats = []\n",
    "\n",
    "work_df = air_df.copy()\n",
    "work_df['Booking_Mode'] = work_df['Booking_Mode'].astype(int)\n",
    "\n",
    "for node, pa in parents.items():\n",
    "    X = work_df[pa].values\n",
    "    y = work_df[node].values\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    pred = model.predict(X)\n",
    "    noise = y - pred\n",
    "\n",
    "    scm_models[node] = model\n",
    "    scm_noise_stats.append(\n",
    "        {\n",
    "            'node': node,\n",
    "            'parents': ', '.join(pa),\n",
    "            'r2': float(model.score(X, y)),\n",
    "            'noise_mean': float(noise.mean()),\n",
    "            'noise_std': float(noise.std(ddof=0)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "q3b_stats = pd.DataFrame(scm_noise_stats).sort_values('node')\n",
    "q3b_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01196a80",
   "metadata": {},
   "source": [
    "### زیربخش سوم (۳ نمره)\n",
    "واریانس سود و سهم مستقیم `Sales_Revenue` و `Operating_Expenses` در واریانس `Profit`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c601939",
   "metadata": {},
   "source": [
    "### زیربخش چهارم (۵ نمره)\n",
    "شناسایی مهم‌ترین عامل سیستم در تغییرپذیری سود (feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3-C and Q3-D: variance decomposition and dominant factors\n",
    "# Direct parent decomposition for Profit = beta1*Sales + beta2*Operating + noise\n",
    "profit_model = scm_models['Profit']\n",
    "beta_sales, beta_op = profit_model.coef_\n",
    "\n",
    "sales = work_df['Sales_Revenue'].to_numpy()\n",
    "op = work_df['Operating_Expenses'].to_numpy()\n",
    "profit = work_df['Profit'].to_numpy()\n",
    "\n",
    "var_profit = float(np.var(profit, ddof=0))\n",
    "var_sales = float(np.var(sales, ddof=0))\n",
    "var_op = float(np.var(op, ddof=0))\n",
    "cov_sales_op = float(np.cov(sales, op, ddof=0)[0, 1])\n",
    "\n",
    "# Shapley-style split of covariance term equally\n",
    "contrib_sales = beta_sales**2 * var_sales + beta_sales * beta_op * cov_sales_op\n",
    "contrib_op = beta_op**2 * var_op + beta_sales * beta_op * cov_sales_op\n",
    "\n",
    "q3c = pd.DataFrame(\n",
    "    {\n",
    "        'component': ['Var(Profit)', 'Sales contribution', 'Operating contribution'],\n",
    "        'value': [var_profit, contrib_sales, contrib_op],\n",
    "        'share_of_profit_var': [1.0, contrib_sales / var_profit, contrib_op / var_profit],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Q3-D: global factor ranking via standardized linear model to Profit\n",
    "feature_cols = [\n",
    "    'Booking_Mode', 'Marketing_Budget', 'Website_Visits',\n",
    "    'Ticket_Price', 'Tickets_Sold', 'Sales_Revenue', 'Operating_Expenses'\n",
    "]\n",
    "Xf = work_df[feature_cols].astype(float)\n",
    "yf = work_df['Profit'].astype(float)\n",
    "\n",
    "Xf_std = (Xf - Xf.mean()) / Xf.std(ddof=0)\n",
    "model_all = LinearRegression().fit(Xf_std, yf)\n",
    "importance = pd.DataFrame({'feature': feature_cols, 'abs_std_coef': np.abs(model_all.coef_)})\n",
    "importance = importance.sort_values('abs_std_coef', ascending=False)\n",
    "\n",
    "print('Q3-C: Direct decomposition of profit variance')\n",
    "display(q3c)\n",
    "print('Q3-D: Dominant system factors (standardized effect magnitude)')\n",
    "display(importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b56290",
   "metadata": {},
   "source": [
    "### زیربخش پنجم (۵ نمره)\n",
    "تحلیل روز اول سال جدید با مقادیر داده‌شده در صورت تمرین"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3-E: First day of new year analysis using provided table values\n",
    "new_year_obs = {\n",
    "    'Booking_Mode': True,\n",
    "    'Marketing_Budget': 2079.01,\n",
    "    'Website_Visits': 21110,\n",
    "    'Ticket_Price': 700.47,\n",
    "    'Tickets_Sold': 7987,\n",
    "    'Sales_Revenue': 5594652.87,\n",
    "    'Operating_Expenses': 4495588.74,\n",
    "    'Profit': 1099064.13,\n",
    "}\n",
    "\n",
    "prev_first_day_profit = float(work_df.iloc[0]['Profit'])\n",
    "delta_profit = new_year_obs['Profit'] - prev_first_day_profit\n",
    "trend = 'increased' if delta_profit > 0 else 'decreased'\n",
    "\n",
    "q3e = pd.DataFrame(\n",
    "    [\n",
    "        {'metric': 'Previous year first-day profit', 'value': prev_first_day_profit},\n",
    "        {'metric': 'New year first-day observed profit', 'value': new_year_obs['Profit']},\n",
    "        {'metric': 'Delta', 'value': delta_profit},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f'Profit {trend} compared to previous-year first day (delta={delta_profit:,.2f}).')\n",
    "q3e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0197b6",
   "metadata": {},
   "source": [
    "## سوال چهارم (۲۲ نمره) | Question 4 (22 Points)\n",
    "هدف: تخمین اثر `insulin` بر `blood_glucose` با استفاده از logistic regression.\n",
    "\n",
    "**شرح نظری کامل / Full theoretical note:**\n",
    "هدف Q4 برآورد اثر علّی انسولین بر قند خون است. اگر $W$ و $Z$ همه مسیرهای backdoor را مسدود کنند، آنگاه $E_{W,Z}E[Y\\mid t,W,Z]$ برآوردگر علّی است. حذف $Z$ یا استفاده از $E[Y\\mid t]$ منجر به بایاس می‌شود. این دقیقا منطق تنظیم‌گری (adjustment) در استنتاج علّی است و دلیل اولویت برآوردگر چندمتغیره در این سؤال است.\n",
    "\n",
    "\n",
    "**نکته تکمیلی Q4 / Q4 extra note:**\n",
    "اگر $Z$ مسیرهای backdoor را نبندد، برآوردگرهای $E_W E[Y\\mid t,W]$ و $E[Y\\mid t]$ بایاس خواهند داشت. بنابراین تنها برآوردگر تنظیم‌شده کامل برای گزارش اثر علّی معتبر است."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28705ee7",
   "metadata": {},
   "source": [
    "### زیربخش محاسباتی (۱۲ نمره)\n",
    "محاسبه سه کمیت:\n",
    "- \\(E_{W,Z}E[Y\\mid t,W,Z]\\)\n",
    "- \\(E_W E[Y\\mid t,W]\\)\n",
    "- \\(E[Y\\mid t]\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_df = data_utils.load_health_dataframe().copy()\n",
    "health_df['high_glucose'] = (health_df['blood_glucose'] >= health_df['blood_glucose'].median()).astype(int)\n",
    "\n",
    "# Define insulin intervention grid in observed range\n",
    "q = np.linspace(0.1, 0.9, 9)\n",
    "t_grid = np.quantile(health_df['insulin'].to_numpy(), q)\n",
    "\n",
    "# Fit logistic models for the three expressions\n",
    "m1 = LogisticRegression(max_iter=2000).fit(health_df[['insulin', 'age', 'blood_pressure']], health_df['high_glucose'])\n",
    "m2 = LogisticRegression(max_iter=2000).fit(health_df[['insulin', 'age']], health_df['high_glucose'])\n",
    "m3 = LogisticRegression(max_iter=2000).fit(health_df[['insulin']], health_df['high_glucose'])\n",
    "\n",
    "def avg_prob_m1(t: float) -> float:\n",
    "    X = health_df[['insulin', 'age', 'blood_pressure']].copy()\n",
    "    X['insulin'] = t\n",
    "    return float(m1.predict_proba(X)[:, 1].mean())\n",
    "\n",
    "def avg_prob_m2(t: float) -> float:\n",
    "    X = health_df[['insulin', 'age']].copy()\n",
    "    X['insulin'] = t\n",
    "    return float(m2.predict_proba(X)[:, 1].mean())\n",
    "\n",
    "def avg_prob_m3(t: float) -> float:\n",
    "    X = pd.DataFrame({'insulin': np.full(len(health_df), t)})\n",
    "    return float(m3.predict_proba(X)[:, 1].mean())\n",
    "\n",
    "q4_res = pd.DataFrame(\n",
    "    {\n",
    "        'insulin_t': t_grid,\n",
    "        'E_WZ_E[Y|t,W,Z]': [avg_prob_m1(t) for t in t_grid],\n",
    "        'E_W_E[Y|t,W]': [avg_prob_m2(t) for t in t_grid],\n",
    "        'E[Y|t]': [avg_prob_m3(t) for t in t_grid],\n",
    "    }\n",
    ")\n",
    "q4_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d32cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8.5, 5))\n",
    "plt.plot(q4_res['insulin_t'], q4_res['E_WZ_E[Y|t,W,Z]'], marker='o', label='E_WZ E[Y|t,W,Z]')\n",
    "plt.plot(q4_res['insulin_t'], q4_res['E_W_E[Y|t,W]'], marker='o', label='E_W E[Y|t,W]  (causal estimator)')\n",
    "plt.plot(q4_res['insulin_t'], q4_res['E[Y|t]'], marker='o', label='E[Y|t]')\n",
    "plt.xlabel('Insulin intervention level t')\n",
    "plt.ylabel('Predicted P(high_glucose=1)')\n",
    "plt.title('Q4 Estimators vs Insulin')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "q4_summary = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            'estimator': 'E_WZ E[Y|t,W,Z]',\n",
    "            'approx_effect (last-first)': float(q4_res['E_WZ_E[Y|t,W,Z]'].iloc[-1] - q4_res['E_WZ_E[Y|t,W,Z]'].iloc[0]),\n",
    "        },\n",
    "        {\n",
    "            'estimator': 'E_W E[Y|t,W] (causal)',\n",
    "            'approx_effect (last-first)': float(q4_res['E_W_E[Y|t,W]'].iloc[-1] - q4_res['E_W_E[Y|t,W]'].iloc[0]),\n",
    "        },\n",
    "        {\n",
    "            'estimator': 'E[Y|t]',\n",
    "            'approx_effect (last-first)': float(q4_res['E[Y|t]'].iloc[-1] - q4_res['E[Y|t]'].iloc[0]),\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "q4_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bcaa28",
   "metadata": {},
   "source": [
    "### زیربخش اثبات اثر علّی (۱۰ نمره)\n",
    "با توجه به DAG سوال ۴:\n",
    "- تنظیم روی \\(W\\) (سن) برای کنترل confounding لازم است.\n",
    "- شرط‌گذاری روی \\(Z\\) (فرزند پس‌مداخله‌ای) می‌تواند bias وارد کند.\n",
    "\n",
    "پس estimator علّی مناسب: **\\(E_W E[Y\\mid t,W]\\)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b80ce",
   "metadata": {},
   "source": [
    "## سوال پنجم (۲۰ نمره) | Question 5 (20 Points)\n",
    "مقایسه‌ی Nearest Counterfactual Explanation و Causal Algorithmic Recourse\n",
    "با دیتاست قرار داده شده در پوشهٔ `dataset` در ریشهٔ HW3.  \n",
    "Dataset path: HW3 root `dataset/` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3343fd8",
   "metadata": {},
   "source": [
    "### زیربخش اول\n",
    "به فایل `data-utils.py` مراجعه نموده و تابع `process_health_data` را طوری تکمیل نمایید که:\n",
    "1. تنها ویژگی‌های `insulin` و `blood_glucose`، actionable باشند.\n",
    "2. مقادیر `blood_pressure`, `insulin`, `blood_glucose` از حداقل/حداکثر دیتاست فراتر نروند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f67898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5-A: verify actionable features and feasible limits\n",
    "X_health, Y_health, constraints = data_utils.process_health_data()\n",
    "\n",
    "q5a = {\n",
    "    'n_samples': int(X_health.shape[0]),\n",
    "    'n_features': int(X_health.shape[1]),\n",
    "    'actionable_indices': constraints['actionable'],\n",
    "    'feature_order': ['age', 'insulin', 'blood_glucose', 'blood_pressure'],\n",
    "    'limits_shape': tuple(constraints['limits'].shape),\n",
    "}\n",
    "\n",
    "q5a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4ad28",
   "metadata": {},
   "source": [
    "### زیربخش دوم\n",
    "`main.py` را به‌ازای ۱۰ فرد ناسالم اجرا کنید و هزینه‌ی محاسبه‌شده را گزارش کنید.\n",
    "\n",
    "در این نوتبوک، معادل این بخش با baseline **SCM-off / nearest style** روی همان ۱۰ فرد گزارش می‌شود.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89735bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5-B and Q5-E: run matched SCM-off vs SCM-on for 10 unhealthy individuals\n",
    "cmd = [sys.executable, str(Q5_DIR / 'run_q5_assignment.py'), '--seed', '0', '--nexplain', '10']\n",
    "subprocess.run(cmd, cwd=str(Q5_DIR), check=True)\n",
    "\n",
    "summary_path = Q5_DIR / 'results' / 'q5_diabetes_summary.csv'\n",
    "per_inst_path = Q5_DIR / 'results' / 'q5_diabetes_per_instance.csv'\n",
    "example_path = Q5_DIR / 'results' / 'q5_diabetes_example.csv'\n",
    "\n",
    "q5_summary = pd.read_csv(summary_path)\n",
    "q5_per_instance = pd.read_csv(per_inst_path)\n",
    "q5_example = pd.read_csv(example_path)\n",
    "\n",
    "print('Q5 summary (SCM off vs on):')\n",
    "display(q5_summary)\n",
    "print('Q5 one-instance comparison:')\n",
    "display(q5_example)\n",
    "print('Q5 per-instance comparison (first 10 rows):')\n",
    "display(q5_per_instance.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2c83d",
   "metadata": {},
   "source": [
    "### زیربخش سوم\n",
    "با مراجعه به `scm.py`، کلاس `Health_SCM` را کامل کنید به‌طوری که:\n",
    "- `insulin` و `blood_glucose` actionable باشند.\n",
    "- `Age` و `blood_pressure` constant features باشند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d0432",
   "metadata": {},
   "source": [
    "### زیربخش چهارم\n",
    "با توجه به ضرایب SCM، تابع `get_Jacobian` را کامل کنید تا ژاکوبین SCM خروجی داده شود.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3eaefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5-C and Q5-D: inspect Health_SCM and Jacobian\n",
    "scmm = utils.get_scm('lin', 'health')\n",
    "J = scmm.get_Jacobian()\n",
    "\n",
    "print('Actionable features in Health_SCM:', scmm.actionable)\n",
    "print('Soft-intervention flags:', scmm.soft_interv)\n",
    "print('SCM coefficients:')\n",
    "print('  w21=', scmm.w21, 'w31=', scmm.w31, 'w32=', scmm.w32, 'w42=', scmm.w42, 'w43=', scmm.w43)\n",
    "print('Jacobian:')\n",
    "print(J)\n",
    "\n",
    "plt.figure(figsize=(5.5, 4.5))\n",
    "sns.heatmap(J, annot=True, fmt='.3f', cmap='Blues',\n",
    "            xticklabels=['age','insulin','blood_glucose','blood_pressure'],\n",
    "            yticklabels=['age','insulin','blood_glucose','blood_pressure'])\n",
    "plt.title('Q5-D Health_SCM Jacobian')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a65cdd",
   "metadata": {},
   "source": [
    "### زیربخش پنجم\n",
    "Comment های بخش `get_scm` در `utils.py` حذف شده و اجرای مجدد با **SCM-on** انجام می‌شود.\n",
    "\n",
    "در این نوتبوک، خروجی SCM-on کنار SCM-off روی همان ۱۰ فرد گزارش شده تا مقایسه مستقیم باشد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315df77",
   "metadata": {},
   "source": [
    "### زیربخش ششم\n",
    "هزینه‌های بخش دوم (SCM-off) و بخش پنجم (SCM-on) را مقایسه کنید.\n",
    "\n",
    "**Grading note:**\n",
    "- `q5_summary`: مقایسه‌ی کلّی هزینه/اعتبار دو روش\n",
    "- `q5_example`: مقایسه‌ی کامل یک فرد نمونه (features + actions + costs)\n",
    "- `q5_per_instance`: مقایسه سطری برای همه‌ی ۱۰ فرد\n",
    "\n",
    "\n",
    "**نتایج عددی Q1 / Q1 numeric results:**\n",
    "\n",
    "| Quantity | Value |\n",
    "|---|---:|\n",
    "| P(Y=1 \\| A=N) | 0.77899 |\n",
    "| P(Y=1 \\| A=O) | 0.82945 |\n",
    "| P(Y=1 \\| do(A=N)) | 0.83200 |\n",
    "| P(Y=1 \\| do(A=O)) | 0.78180 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4a329",
   "metadata": {},
   "source": [
    "### تحلیل تکمیلی (اختیاری برای نمره کامل)\n",
    "بهینه‌سازی و تحلیل پایداری بر حسب robustness radius (epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c09dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 optimization: epsilon sweep for linear recourse (SCM off/on)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X, Y, cons = data_utils.process_data('health')\n",
    "X_train, Y_train, X_test, Y_test = data_utils.train_test_split(X, Y)\n",
    "\n",
    "model_path = Q5_DIR / 'models' / 'health_ERM_lin_s0.pth'\n",
    "if not model_path.exists():\n",
    "    _ = train_classifiers.train('health', 'ERM', 'lin', utils.get_train_epochs('health', 'lin', 'ERM'), 0, 0, save_model=True)\n",
    "\n",
    "model = trainers.LogisticRegression(X_train.shape[-1], actionable_features=cons['actionable'], actionable_mask=False)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "model.set_max_mcc_threshold(X_train, Y_train)\n",
    "\n",
    "id_neg = model.predict(X_test) == 0\n",
    "X_neg = X_test[id_neg]\n",
    "idx = np.random.choice(np.arange(X_neg.shape[0]), size=min(10, X_neg.shape[0]), replace=False)\n",
    "X_exp = X_neg[idx]\n",
    "\n",
    "def eval_eps(eps: float, scm_on: bool):\n",
    "    w, b = model.get_weights()\n",
    "    scm_obj = utils.get_scm('lin', 'health') if scm_on else None\n",
    "    Jw = w if scm_obj is None else scm_obj.get_Jacobian().T @ w\n",
    "    dual_norm = np.sqrt(Jw.T @ Jw)\n",
    "    explainer = recourse.LinearRecourse(w, b + dual_norm * eps)\n",
    "    _, valids, costs, _, _ = recourse.causal_recourse(X_exp, explainer, cons, scm=scm_obj, verbose=False)\n",
    "    valids = np.asarray(valids).astype(bool)\n",
    "    costs = np.asarray(costs)\n",
    "    return float(valids.mean()), float(costs[valids].mean()) if valids.any() else np.nan\n",
    "\n",
    "rows = []\n",
    "for eps in [0.0, 0.1, 0.2]:\n",
    "    for scm_on in [False, True]:\n",
    "        vr, vc = eval_eps(eps, scm_on)\n",
    "        rows.append({'epsilon': eps, 'method': 'SCM-on' if scm_on else 'SCM-off', 'valid_rate': vr, 'valid_cost': vc})\n",
    "\n",
    "q5_eps = pd.DataFrame(rows)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
    "sns.lineplot(data=q5_eps, x='epsilon', y='valid_rate', hue='method', marker='o', ax=axes[0])\n",
    "sns.lineplot(data=q5_eps, x='epsilon', y='valid_cost', hue='method', marker='o', ax=axes[1])\n",
    "axes[0].set_title('Validity vs epsilon')\n",
    "axes[1].set_title('Valid cost vs epsilon')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "q5_eps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e70a4",
   "metadata": {},
   "source": [
    "## سوال ششم (۱۶ نمره) | Question 6 (16 Points)\n",
    "Paper: *On the Adversarial Robustness of Causal Algorithmic Recourse*\n",
    "\n",
    "**شرح نظری کامل / Full theoretical note:**\n",
    "نتیجه کلیدی مقاله این است که در حضور SCM، عدم‌قطعیت ورودی‌ها از طریق Jacobian علّی به فضای مداخله منتقل می‌شود؛ بنابراین شرط robust recourse به یک margin shift وابسته به $\\|J^T w\\|$ تبدیل می‌گردد. این موضوع هم نظری است (برای مدل خطی قابل اثبات) و هم تجربی (در نمودارهای هزینه-اعتبار مشاهده می‌شود). همچنین به ما می‌گوید چرا recourse غیرعلّی می‌تواند پرهزینه‌تر شود: چون اثرات زنجیره‌ای مداخله را نادیده می‌گیرد.\n",
    "\n",
    "\n",
    "**نکته تکمیلی Q6 / Q6 extra note:**\n",
    "کران robust در مدل خطی معادل یک margin shift به اندازه $\\epsilon\\|J^T w\\|_2$ است؛ این دقیقاً توضیح می‌دهد چرا نمودارهای هزینه با افزایش $\\epsilon$ رشد می‌کنند و چرا SCM (از طریق $J$) هزینه را تغییر می‌دهد."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1146c9",
   "metadata": {},
   "source": [
    "### زیربخش اول (۸ نمره)\n",
    "تحت چه شرایطی robustness در classifier و SCM تضمین می‌شود؟\n",
    "\n",
    "- classifier خطی یا locally linear\n",
    "- SCM درست‌مشخص‌شده و مشتق‌پذیر\n",
    "- مجموعه مداخله محدب و قیود صریح\n",
    "- uncertainty bounded (مثل ||delta||_2 <= epsilon)\n",
    "- حل robust با margin shift دوگان مناسب\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048befb",
   "metadata": {},
   "source": [
    "### زیربخش دوم (۸ نمره)\n",
    "شهود Proposition 4 و معادله (5):\n",
    "\n",
    "برای score خطی و SCM Jacobian داریم:\n",
    "`w^T(x+Ja) >= b + epsilon * ||J^T w||_*`\n",
    "\n",
    "یعنی مرز تصمیم nominal کافی نیست؛ باید حاشیه‌ای متناسب با بدترین اغتشاش و propagation علّی عبور شود.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68ffa9",
   "metadata": {},
   "source": [
    "## خروجی‌های نهایی برای تصحیح | Export Artifacts for Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_res.to_csv(OUT_DIR / 'q1_results.csv', index=False)\n",
    "q2_res.to_csv(OUT_DIR / 'q2_results.csv', index=False)\n",
    "q3b_stats.to_csv(OUT_DIR / 'q3_scm_fit_stats.csv', index=False)\n",
    "q3c.to_csv(OUT_DIR / 'q3_variance_decomposition.csv', index=False)\n",
    "importance.to_csv(OUT_DIR / 'q3_factor_importance.csv', index=False)\n",
    "q4_res.to_csv(OUT_DIR / 'q4_estimators_curve.csv', index=False)\n",
    "q4_summary.to_csv(OUT_DIR / 'q4_estimators_summary.csv', index=False)\n",
    "q5_summary.to_csv(OUT_DIR / 'q5_summary.csv', index=False)\n",
    "q5_per_instance.to_csv(OUT_DIR / 'q5_per_instance.csv', index=False)\n",
    "q5_example.to_csv(OUT_DIR / 'q5_example.csv', index=False)\n",
    "q5_eps.to_csv(OUT_DIR / 'q5_epsilon_sweep.csv', index=False)\n",
    "\n",
    "print('Saved notebook artifacts under:', OUT_DIR)\n",
    "for p in sorted(OUT_DIR.glob('*.csv')):\n",
    "    print('-', p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a4884",
   "metadata": {},
   "source": [
    "## چک‌لیست نهایی تحویل | Final Grading Checklist\n",
    "\n",
    "- [x] Q1 چهار کمیت احتمالاتی (obs + do)\n",
    "- [x] Q2 حالت بهینه و هزینه برای A و B\n",
    "- [x] Q3 پنج زیربخش (graph, SCM, variance, dominant factor, first-day analysis)\n",
    "- [x] Q4 سه estimator + تشخیص estimator علّی\n",
    "- [x] Q5 زیربخش‌های ۱ تا ۶ + مقایسه نمونه‌محور\n",
    "- [x] Q6 دو پاسخ نظری کامل\n",
    "- [x] CSV artifacts exported under `output/jupyter-notebook/artifacts`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa8d1c9",
   "metadata": {},
   "source": [
    "## دستورات اجرای سریع | Quick Re-run Commands\n",
    "\n",
    "Activate your virtualenv, then from the HW3 root directory run:\n",
    "\n",
    "```bash\n",
    "cd <HW3_ROOT>\n",
    "jupyter lab code/HW3_complete_assignment.ipynb\n",
    "```\n",
    "\n",
    "Or run the setup cell at the top to resolve `ROOT`; then use `cd $ROOT` (or the path it prints).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
