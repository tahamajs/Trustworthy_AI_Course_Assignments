\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathpazo}
\usepackage{microtype}
\usepackage[a4paper,margin=1in]{geometry}
\setlength{\headheight}{15pt}

\usepackage{amsmath,amssymb,mathtools}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{float}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{listings}

\definecolor{accent}{HTML}{2A9D8F}
\definecolor{heading}{HTML}{264653}
\definecolor{codebg}{HTML}{F7F7F7}

\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries\color{heading}}{\thesection}{1em}{}
\titleformat{\subsection}{\bfseries\color{heading}}{\thesubsection}{0.5em}{}
\titlespacing*{\section}{0pt}{12pt}{6pt}

\lstdefinestyle{plainstyle}{
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{codebg},
  frame=single,
  framesep=4pt,
  rulecolor=\color{gray!40},
  breaklines=true,
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny\color{gray}
}
\lstset{style=plainstyle}

\usepackage{tcolorbox}
\tcbset{colback=gray!7, colframe=accent, left=6pt, right=6pt, boxrule=0.8pt}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.6pt}
\renewcommand{\footrulewidth}{0.0pt}
\fancyhead[L]{\small\textbf{Trusted Artificial Intelligence}}
\fancyhead[C]{\small Homework 3}
\fancyhead[R]{\small Taha Majlesi}
\fancyfoot[C]{\thepage}

\newcommand{\course}{Trusted Artificial Intelligence}
\newcommand{\instructor}{Dr. Mostafa Tavasolipour}
\newcommand{\semester}{Spring 2024}
\newcommand{\assignment}{3}
\newcommand{\authorname}{Taha Majlesi}
\newcommand{\studentid}{810101504}
\newcommand{\affiliation}{Department of Electrical and Computer Engineering, University of Tehran}

\usepackage[hidelinks]{hyperref}
\usepackage{natbib}
\bibliographystyle{plainnat}

\begin{document}

\begin{titlepage}
  \centering
  {\LARGE\bfseries \course{} \par}
  \vspace{1.2cm}
  {\Huge\bfseries Homework \assignment{} \par}
  \vspace{0.6cm}
  {\large \semester{} \par}
  \vspace{1.2cm}
  {\Large\bfseries \authorname{} \par}
  \vspace{0.2cm}
  {\small ID: \studentid{} \quad | \quad \affiliation{} \par}
  \vfill
  {\large Instructor: \instructor{} \par}
  {\small Submitted: \today \par}
\end{titlepage}

\begin{tcolorbox}
\textbf{Abstract.}
This report provides a complete long-form implementation report for the causal recourse part of HW3 (Question 5)
using the health dataset. The pipeline is fully executable from local code, including: (1) constrained data
processing and actionability, (2) classifier training for linear and MLP models, (3) completed health SCM and Jacobian,
(4) recourse evaluation across robustness radii, and (5) automatic export of publication-ready report figures.

The document includes direct answers to each Q5 sub-question, equations, implementation traceability (file-level),
reproducibility commands, aggregated quantitative results over multiple seeds, and error analysis. In addition,
Nearest Counterfactual and Causal Algorithmic Recourse are compared empirically under matched conditions.
\end{tcolorbox}

\vspace{6pt}
\tableofcontents
\clearpage

\section{Scope and Completion Statement}
The practical deliverable in this repository is the causal recourse implementation located under
\texttt{code/Q5\_codes}. This report therefore focuses on full completion of Question 5 requirements from the assignment,
including data constraints, SCM completion, Jacobian completion, and quantitative comparison of recourse methods.

\subsection{What is completed}
The following deliverables are complete and verified by executable runs:
\begin{itemize}[leftmargin=1.2em]
  \item Health data processing constraints for actionable features and feature bounds.
  \item End-to-end training and evaluation for linear and MLP classifiers.
  \item Full \texttt{Health\_SCM} implementation with structural equations, inverse mapping, and Jacobian.
  \item Recourse runs for 10 negatively classified instances under multiple robustness radii.
  \item Automatic generation of report artifacts (figures and summary CSV tables).
  \item PDF report build with included results and reproducibility commands.
\end{itemize}

\subsection{Key modified files}
\begin{itemize}[leftmargin=1.2em]
  \item \texttt{code/Q5\_codes/scm.py}
  \item \texttt{code/Q5\_codes/evaluate\_recourse.py}
  \item \texttt{code/Q5\_codes/utils.py}
  \item \texttt{code/Q5\_codes/plot\_report\_figures.py}
  \item \texttt{code/Q5\_codes/generate\_report\_artifacts.py}
  \item \texttt{report/figures/*.png}
\end{itemize}

\section{Problem Setup (Question 5)}
Question 5 asks for two recourse styles on the health dataset:
\begin{enumerate}
  \item Nearest Counterfactual Explanation (SCM disabled / independently manipulable assumption).
  \item Causal Algorithmic Recourse (SCM enabled; intervention effects propagate through causal structure).
\end{enumerate}
This setup follows standard recourse formulations in actionable and causal recourse literature
\citep{ustun2019actionable,karimi2021algorithmic,karimi2020algorithmic}.

The classifier input variables are:
\begin{itemize}[leftmargin=1.2em]
  \item \texttt{age}
  \item \texttt{insulin}
  \item \texttt{blood\_glucose}
  \item \texttt{blood\_pressure}
\end{itemize}

The target is \texttt{category} with label 0 = unhealthy, 1 = healthy.

\section{Methodology and Equations}
\subsection{Classifier objective}
For a classifier score function $g_\theta(x)$ and threshold $\tau$, prediction is:
\begin{equation}
\hat{y} = \mathbb{I}[\sigma(g_\theta(x)) \ge \tau].
\end{equation}

Threshold $\tau$ is calibrated using max-MCC on the training split.

\subsection{Nearest counterfactual recourse}
For linear models, the recourse action $a$ solves:
\begin{equation}
\min_a \; \|c \odot a\|_1
\quad\text{s.t.}\quad
\langle w, x + a \rangle \ge b,
\end{equation}
plus actionability and bound constraints. In this mode, SCM is disabled and each feature can be modified only through
its own action constraint.

\subsection{Causal algorithmic recourse}
With SCM enabled, interventions on actionable variables propagate via structural equations. For a factual instance
$x^{(n)}$ and intervention $\delta$, counterfactual generation uses:
\begin{equation}
X_{\mathrm{cf}} = f\bigl(U(X), \delta\bigr),
\end{equation}
where $U(X)$ is obtained by abduction via inverse structural equations.
The abduction-action-prediction decomposition follows structural causal modeling principles
\citep{pearl2009causality}.

\subsection{Health SCM used in this implementation}
Feature order is $[\text{age},\text{insulin},\text{blood\_glucose},\text{blood\_pressure}]$.
The completed linear structural equations are:
\begin{align}
X_1 &= U_1, \\
X_2 &= w_{21} X_1 + U_2, \quad w_{21}=\frac{1}{18}, \\
X_3 &= w_{31} X_1 + w_{32} X_2 + U_3, \quad w_{31}=2.0,\; w_{32}=1.05, \\
X_4 &= w_{42} X_2 + w_{43} X_3 + U_4, \quad w_{42}=0.4,\; w_{43}=0.3.
\end{align}

The corresponding Jacobian is:
\begin{equation}
J =
\begin{bmatrix}
1 & 0 & 0 & 0 \\
w_{21} & 1 & 0 & 0 \\
w_{31} & w_{32} & 1 & 0 \\
0 & w_{42} & w_{43} & 1
\end{bmatrix}.
\end{equation}

\section{Direct Answers to Question 5 Sub-Questions}
\subsection{Q5.1: Completing \texttt{process\_health\_data}}
Implemented behavior:
\begin{itemize}[leftmargin=1.2em]
  \item Actionable features: only \texttt{insulin} and \texttt{blood\_glucose}.
  \item Non-actionable features: \texttt{age}, \texttt{blood\_pressure}.
  \item Feature bounds: interventions are clamped to observed dataset min/max for bounded variables.
\end{itemize}
This is encoded in preprocessing constraints consumed by recourse algorithms.

\subsection{Q5.2: Running for 10 unhealthy individuals and reporting cost}
Using $N_{\text{explain}}=10$ on health data, the linear ERM model with SCM enabled reports:
\begin{itemize}[leftmargin=1.2em]
  \item Seed 0, $\epsilon=0$: valid recourse rate = 1.00, mean valid cost $\approx 0.909$.
\end{itemize}
Across seeds 0,1,2 (aggregated):
\begin{itemize}[leftmargin=1.2em]
  \item Mean valid cost (lin-ERM, $\epsilon=0$): \textbf{0.889}.
\end{itemize}
Interpretation: this cost is the mean magnitude of actionable intervention (L1 norm) needed to flip prediction
from unhealthy to healthy while respecting actionability and feasibility constraints.

\subsection{Q5.3: Completing \texttt{Health\_SCM}}
The class was completed with:
\begin{itemize}[leftmargin=1.2em]
  \item Structural equations \texttt{self.f}.
  \item Inverse equations \texttt{self.inv\_f} for abduction.
  \item Actionability definition: \texttt{[1,2]} (insulin and blood glucose).
  \item Hard intervention semantics for actionable variables.
\end{itemize}
This completion is necessary for causal (not merely nearest) recourse and for differentiable recourse on MLP models.

\subsection{Q5.4: Completing \texttt{get\_Jacobian}}
The Jacobian was completed exactly from the assumed linear SCM coefficients above and used by linear recourse.

\subsection{Q5.5: Rerun with SCM enabled and report cost}
With SCM enabled, linear ERM recourse remains fully valid (rate 1.00 for tested runs).
For seed 0 and $N_{\text{explain}}=10$:
\begin{itemize}[leftmargin=1.2em]
  \item Causal recourse mean valid cost: \textbf{0.625} (matched comparison setup in Section~\ref{sec:nvscausal}).
\end{itemize}
Cost here represents intervention effort after propagating causal effects through the structural equations.

\subsection{Q5.6: Compare Nearest Counterfactual and Causal Recourse}
\label{sec:nvscausal}
Using the same linear ERM model (seed 0) and same sampled unhealthy individuals:
\begin{itemize}[leftmargin=1.2em]
  \item Nearest Counterfactual (SCM off): valid rate = 1.00, mean cost = 0.779.
  \item Causal Recourse (SCM on): valid rate = 1.00, mean cost = 0.625.
\end{itemize}
In this dataset/model configuration, causal propagation reduces average intervention cost while preserving full validity.

\section{Experimental Protocol}
\subsection{Environment}
\begin{itemize}[leftmargin=1.2em]
  \item Python environment activated with:
  \verb|source /Users/tahamajs/Documents/uni/venv/bin/activate|
  \item Main code directory: \texttt{HomeWorks/HW3/code/Q5\_codes}
  \item Report directory: \texttt{HomeWorks/HW3/report}
\end{itemize}

\subsection{Models and settings}
\begin{table}[H]
\centering
\caption{Evaluated model/trainer settings on health dataset}
\label{tab:settings}
\begin{tabular}{llll}
\toprule
Model & Trainer & Seeds & Epsilon values \\
\midrule
Linear & ERM & 0,1,2 & 0.0, 0.1, 0.2 \\
Linear & AF  & 0,1,2 & 0.0, 0.1, 0.2 \\
MLP    & ERM & 0,1   & 0.0, 0.1, 0.2 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Generated artifacts}
The script \texttt{generate\_report\_artifacts.py} writes:
\begin{itemize}[leftmargin=1.2em]
  \item \texttt{code/Q5\_codes/results/health\_report\_summary.csv}
  \item \texttt{code/Q5\_codes/results/health\_report\_aggregate.csv}
  \item \texttt{code/Q5\_codes/results/nearest\_vs\_causal\_lin\_seed0.csv}
  \item Figures under \texttt{report/figures/}
\end{itemize}

\section{Quantitative Results}
\subsection{Classifier quality}
\begin{table}[H]
\centering
\caption{Classifier metrics (test split, mean $\pm$ std across seeds)}
\label{tab:clfmetrics}
\begin{tabular}{lcc}
\toprule
Configuration & Accuracy & MCC \\
\midrule
lin-ERM & $0.903 \pm 0.002$ & $0.803 \pm 0.004$ \\
lin-AF  & $0.903 \pm 0.002$ & $0.803 \pm 0.003$ \\
mlp-ERM & $1.000 \pm 0.000$ & $1.000 \pm 0.000$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.72\textwidth]{figures/classifier_metrics.png}
  \caption{Accuracy and MCC by configuration (error bars from available seeds).}
  \label{fig:clfmetrics}
\end{figure}

\subsection{Recourse validity and cost across robustness radii}
\begin{table}[H]
\centering
\caption{Recourse outcomes (mean over seeds)}
\label{tab:recourseagg}
\begin{tabular}{lccc}
\toprule
Configuration & $\epsilon$ & Valid rate & Mean valid cost \\
\midrule
lin-ERM & 0.0 & 1.00 & 0.889 \\
lin-ERM & 0.1 & 1.00 & 1.004 \\
lin-ERM & 0.2 & 1.00 & 1.120 \\
lin-AF  & 0.0 & 1.00 & 0.701 \\
lin-AF  & 0.1 & 1.00 & 0.823 \\
lin-AF  & 0.2 & 1.00 & 0.946 \\
mlp-ERM & 0.0 & 0.85 & 1.111 \\
mlp-ERM & 0.1 & 0.90 & 1.253 \\
mlp-ERM & 0.2 & 0.90 & 0.885 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.72\textwidth]{figures/valid_rate_vs_epsilon.png}
  \caption{Valid recourse rate as robustness radius increases.}
  \label{fig:validrate}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.72\textwidth]{figures/valid_cost_vs_epsilon.png}
  \caption{Mean cost of valid recourse vs robustness radius.}
  \label{fig:validcost}
\end{figure}

\subsection{Instance-level recourse evidence}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.72\textwidth]{figures/recourse_costs.png}
  \caption{Per-instance recourse costs for explained unhealthy individuals (example run).}
  \label{fig:instancecost}
\end{figure}

\subsection{Nearest vs causal comparison}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{figures/nearest_vs_causal.png}
  \caption{Direct comparison of Nearest Counterfactual and Causal Recourse (lin-ERM, seed 0).}
  \label{fig:nvscausal}
\end{figure}

\section{Discussion}
\subsection{Main findings}
\begin{itemize}[leftmargin=1.2em]
  \item Linear models (ERM and AF) achieved stable, high validity for all tested robustness radii.
  \item AF regularization reduced intervention costs relative to ERM at every tested $\epsilon$.
  \item Causal recourse improved intervention efficiency compared with nearest counterfactual under the matched setup.
\end{itemize}

\subsection{Why cost increases with $\epsilon$ in linear models}
For robust linear recourse, increasing $\epsilon$ effectively tightens the decision constraint by accounting for uncertainty
around the decision boundary. As expected, higher robustness requirements demand larger interventions, which is reflected
in monotonic cost growth for lin-ERM and lin-AF.

\subsection{On perfect MLP classifier scores}
The MLP reached perfect test metrics for available seeds in this split. This can happen due dataset size/split structure
and model capacity. Recourse validity is still below 1.0 for MLP runs, indicating that prediction quality alone does not
guarantee easy recourse, consistent with prior observations in counterfactual explanation studies
\citep{mothilal2020explaining}.

\section{Error Analysis and Threats to Validity}
\subsection{Modeling assumptions}
The health SCM is linear and additive-noise. Real physiological mechanisms are likely nonlinear and partially latent.
Therefore, absolute recourse costs should be interpreted as model-conditional rather than causal ground truth.

\subsection{Finite-sample and split sensitivity}
Results are estimated on finite seeds and fixed train/test split routine. Additional seeds and stratified splits can
change quantitative values, especially for MLP recourse.

\subsection{Optimization effects}
Differentiable recourse for MLP relies on iterative optimization and can be sensitive to hyperparameters. This is one
reason to report both validity and cost instead of only one metric.

\section{Reproducibility Checklist}
\subsection{Core commands}
\begin{lstlisting}[caption={Primary commands used for completion and reporting}]
cd /Users/tahamajs/Documents/uni/truthlyAI/HomeWorks/HW3/code/Q5_codes
source /Users/tahamajs/Documents/uni/venv/bin/activate

# End-to-end benchmark
python main.py --seed 0

# Build additional report artifacts and figures
python generate_report_artifacts.py

# Build PDF report
cd /Users/tahamajs/Documents/uni/truthlyAI/HomeWorks/HW3/report
make pdf
\end{lstlisting}

\subsection{Determinism}
All reported experiments used explicit seed control in training/evaluation scripts. Report aggregates state seed count
for each configuration.

\section{Conclusion}
This submission completes the causal recourse implementation pipeline for HW3 Question 5 in a fully runnable form.
All required software components (constraints, SCM, Jacobian, recourse evaluation, and figure export) are implemented,
validated, and documented with direct evidence. The empirical comparison shows that causal recourse can preserve validity
while reducing intervention cost relative to nearest counterfactual recommendations in the tested setting.

\appendix
\section{Implementation Traceability Matrix}
\begin{longtable}{p{0.16\textwidth}p{0.22\textwidth}p{0.22\textwidth}p{0.32\textwidth}}
\toprule
Requirement & File & Function/Class & Evidence \\
\midrule
\endfirsthead
\toprule
Requirement & File & Function/Class & Evidence \\
\midrule
\endhead
Q5.1 constraints & \texttt{code/Q5\_codes/data\_utils.py} & \texttt{process\_health\_data} & Actionable set and feature limits consumed by recourse \\
Q5.2 run on 10 unhealthy & \texttt{code/Q5\_codes/evaluate\_recourse.py} & \texttt{eval\_recourse} & Saved \texttt{\_valid.npy} and \texttt{\_cost.npy} files \\
Q5.3 SCM completion & \texttt{code/Q5\_codes/scm.py} & \texttt{Health\_SCM} & Structural and inverse equations added \\
Q5.4 Jacobian completion & \texttt{code/Q5\_codes/scm.py} & \texttt{get\_Jacobian} & Closed-form Jacobian matrix used by linear recourse \\
Q5.5 SCM-enabled rerun & \texttt{code/Q5\_codes/utils.py} & \texttt{get\_scm} & Health SCM loaded by evaluation pipeline \\
Q5.6 method comparison & \texttt{code/Q5\_codes/generate\_report\_artifacts.py} & \texttt{nearest\_vs\_causal\_lin} & CSV and figure \texttt{nearest\_vs\_causal.png} \\
Figure export & \texttt{code/Q5\_codes/plot\_report\_figures.py} & \texttt{export\_report\_plots} & \texttt{recourse\_costs.png}, summary plots \\
\bottomrule
\end{longtable}

\section{Aggregated CSV Evidence}
\subsection{Aggregate metrics table (auto-generated)}
\lstinputlisting[caption={\texttt{health\_report\_aggregate.csv}}]{../code/Q5_codes/results/health_report_aggregate.csv}

\subsection{Nearest-vs-causal comparison table (auto-generated)}
\lstinputlisting[caption={\texttt{nearest\_vs\_causal\_lin\_seed0.csv}}]{../code/Q5_codes/results/nearest_vs_causal_lin_seed0.csv}

\clearpage
\bibliography{references}
\end{document}
